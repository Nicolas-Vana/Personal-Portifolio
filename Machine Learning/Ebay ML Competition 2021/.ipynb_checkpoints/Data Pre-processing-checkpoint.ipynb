{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59204c6b",
   "metadata": {},
   "source": [
    "# Ebay ML competition 2021 - Prepocessing\n",
    "\n",
    "In this notebook we are going to treat the data from the Ebay ML competition from 2021. Pre-processing includes transformation of dates, one-hot encoding, feature extraction and other methods. Because the data provided is not public, a new reduced dataset was created and will be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9443e583",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Zipcode' from 'uszipcode' (C:\\Users\\nicol\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\uszipcode\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33620/2324839537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0muszipcode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSearchEngine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0muszipcode\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mZipcode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholiday\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUSFederalHolidayCalendar\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffsets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCustomBusinessDay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Zipcode' from 'uszipcode' (C:\\Users\\nicol\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\uszipcode\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from uszipcode import SearchEngine\n",
    "from uszipcode import Zipcode\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from datetime import datetime, date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('eBay_ML_Challenge_Dataset_2021')\n",
    "\n",
    "tsv_file = open(\"train reduced fake.csv\", encoding='utf-8')\n",
    "\n",
    "# Takes 1 min to load if all rows are enabled\n",
    "df = pd.read_csv(tsv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtains state data for all the zipcodes\n",
    "search = SearchEngine()\n",
    "\n",
    "buyer_state = []\n",
    "item_state = []\n",
    "\n",
    "for zipc in df['buyer_zip']:\n",
    "    \n",
    "    zipcode = search.by_zipcode(zipc)\n",
    "    \n",
    "    # Catch zipcodes that were not found\n",
    "    try:\n",
    "        buyer_state.append(zipcode.state_abbr)\n",
    "    except:\n",
    "        buyer_state.append('-1')\n",
    "\n",
    "\n",
    "\n",
    "for zipc in df['item_zip'].tolist():\n",
    "    \n",
    "    zipcode = search.by_zipcode(zipc)\n",
    "    \n",
    "    # Catch zipcodes that were not found\n",
    "    try:\n",
    "        item_state.append(zipcode.state_abbr)\n",
    "    except:\n",
    "        item_state.append('-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3098725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add location columns to dataframe\n",
    "df['buyer_state'] = buyer_state\n",
    "df['item_state'] = item_state\n",
    "\n",
    "df['buyer_state'] = df['buyer_state'].astype(str)\n",
    "df['item_state'] = df['item_state'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pounds to kg and remove weight units column.\n",
    "\n",
    "tmp = df[df['weight_units'] == 2]\n",
    "tmp['weight'] = tmp['weight']*2.20462\n",
    "\n",
    "df.drop(columns = ['weight_units'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcbfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude weekends and US federal holidays\n",
    "dr = pd.date_range(start='2018-01-01', end='2020-12-31')\n",
    "fed_hol = pd.DataFrame()\n",
    "fed_hol['Date'] = dr\n",
    "\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "\n",
    "fed_hol['Holiday'] = fed_hol['Date'].isin(holidays)\n",
    "hld = fed_hol[fed_hol['Holiday']==1].values.astype('datetime64[D]')\n",
    "\n",
    "handling_time = []\n",
    "total_time_bd = []\n",
    "\n",
    "for t in range(df.shape[0]):\n",
    "    \n",
    "    # determine number of days for delivery. Use only business days to finde this\n",
    "    acceptance_time = datetime.fromisoformat(df['acceptance_scan_timestamp'][t][0:10])\n",
    "    payment_time = datetime.fromisoformat(df['payment_datetime'][t][0:10])\n",
    "    handling_time.append(np.busday_count(df['payment_datetime'][t][0:10], df['acceptance_scan_timestamp'][t][0:10], holidays = hld.flatten()))\n",
    "    total_time_bd.append(np.busday_count(df['payment_datetime'][t][0:10], df['delivery_date'][t],holidays = hld.flatten()))\n",
    "    \n",
    "    #if payment is made past cutoff on a weekday, it is considered next business day\n",
    "    if payment_time.hour >= 14 and payment_time.weekday() < 5:\n",
    "        total_time_bd[t] = total_time_bd[t] - 1\n",
    "    \n",
    "\n",
    "df['delivery_time_buss_days'] = total_time_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the timestamps to datetime instead of strings\n",
    "\n",
    "df['acceptance_scan_timestamp'] = pd.to_datetime(df['acceptance_scan_timestamp'], format = '%Y-%m-%d %H:%M:%S', utc = True)\n",
    "df['payment_datetime'] = pd.to_datetime(df['payment_datetime'], format = '%Y-%m-%d %H:%M:%S', utc = True)\n",
    "df['delivery_date'] = pd.to_datetime(df['delivery_date'], format = '%Y-%m-%d', utc = True)\n",
    "\n",
    "# Obtain datetimes as timestamps and calculate time in seconds.\n",
    "df['acceptance_scan_timestamp seconds'] = (df['acceptance_scan_timestamp'].values.astype(np.int64)/10**9).astype(int)\n",
    "df['payment_datetime seconds'] = (df['payment_datetime'].values.astype(np.int64)/10**9).astype(int)\n",
    "df['delivery_date seconds'] = (df['delivery_date'].values.astype(np.int64)/10**9).astype(int)\n",
    "\n",
    "# Create the True handling time column and true handling time in seconds (because then it can be used as an integer values)\n",
    "#df['true handling time'] = df['acceptance_scan_timestamp'] - df['payment_datetime']\n",
    "#df['true handling time seconds'] = (df['true handling time'].values.astype(np.int64)/10**9).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8170024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving missing weight values by substituting with the mean/median\n",
    "\n",
    "tmp = df[df['weight'] > 0].copy()\n",
    "mean = np.mean(tmp['weight'])\n",
    "median = np.median(tmp['weight'])\n",
    "\n",
    "new_weight = np.where(df['weight'] > 0, df['weight'], median)\n",
    "df['new_weight'] = new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183479c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving missing declared_handling_days values by substituting with the mean/median. Mean might be better in this case.\n",
    "\n",
    "tmp = df[df['declared_handling_days'].notnull()].copy()\n",
    "mean = np.mean(tmp['declared_handling_days'])\n",
    "median = np.median(tmp['declared_handling_days'])\n",
    "\n",
    "df['new_declared_handling_days'] = df['declared_handling_days']\n",
    "df['new_declared_handling_days'].fillna(mean, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426ff667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the numerical variables as numerical variables (they come as strings). Save this version of the\n",
    "# Dataframe as it is the one with all the columns and now we will keep only the desired columns.\n",
    "\n",
    "df['shipment_method_id'] = df['shipment_method_id'].astype(int)\n",
    "df['shipping_fee'] = df['shipping_fee'].astype(float)\n",
    "df['carrier_min_estimate'] = df['carrier_min_estimate'].astype(int)\n",
    "df['carrier_max_estimate'] = df['carrier_max_estimate'].astype(int)\n",
    "df['category_id'] = df['category_id'].astype(int)\n",
    "df['item_price'] = df['item_price'].astype(float)\n",
    "df['quantity'] = df['quantity'].astype(int)\n",
    "df['new_weight'] = df['new_weight'].astype(int)\n",
    "df['new_declared_handling_days'] = df['new_declared_handling_days'].astype(int)\n",
    "\n",
    "df.to_csv('Complete dataset 100 rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22302728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we drop all the unnecessary columns and save again\n",
    "\n",
    "df.drop(columns = (['item_zip', 'buyer_zip', 'weight', 'declared_handling_days', 'record_number']), inplace = True)\n",
    "\n",
    "df.to_csv('No useless columns dataset 100 rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we drop all columns that have updated versions\n",
    "\n",
    "df.drop(columns = (['acceptance_scan_timestamp', 'payment_datetime', 'delivery_date']), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db55a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we do the One-Hot encodings.\n",
    "\n",
    "for column in df.columns.tolist():\n",
    "    if df[column].dtype == 'object':\n",
    "        print(column)\n",
    "        tmp = pd.get_dummies(df[column], prefix = column).astype(int)\n",
    "        tmp.where(tmp == 1, -1, inplace = True)\n",
    "\n",
    "        df = df.join(tmp)\n",
    "\n",
    "cat_cols = ['shipment_method_id', 'category_id'] \n",
    "for column in cat_cols:\n",
    "    \n",
    "    print(column)\n",
    "    tmp = pd.get_dummies(df[column], prefix = column).astype(int)\n",
    "    tmp.where(tmp == 1, -1, inplace = True)\n",
    "\n",
    "    df = df.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cedafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we drop the columns that were transformed\n",
    "\n",
    "df.drop(columns = (['b2c_c2c', 'package_size', 'buyer_state', 'item_state', 'seller_id']), inplace = True)\n",
    "df.drop(columns = (cat_cols), inplace = True)\n",
    "\n",
    "df.to_csv('Only numerical dataset all rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we normalize the data numerical data\n",
    "real_cols = ['shipping_fee',\n",
    " 'carrier_min_estimate',\n",
    " 'carrier_max_estimate',\n",
    " 'item_price',\n",
    " 'quantity',\n",
    " 'acceptance_scan_timestamp seconds',\n",
    " 'payment_datetime seconds',\n",
    " 'new_weight',\n",
    " 'new_declared_handling_days']\n",
    "\n",
    "for column in real_cols:\n",
    "    mean = np.mean(df[column])\n",
    "    std = np.std(df[column])\n",
    "    df[column] = (df[column] - mean)/std\n",
    "\n",
    "df.to_csv('Only numerical dataset normalized 100 rows.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb8b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
