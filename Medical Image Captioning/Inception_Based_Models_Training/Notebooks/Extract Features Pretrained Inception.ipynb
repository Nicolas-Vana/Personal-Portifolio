{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee0ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52d2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.absolute()) \n",
    "\n",
    "preprocessed_image_path = root / 'Shared Preprocessed Objects' / 'Preprocessed Images for Inception'\n",
    "model_path = root / 'Models' / 'Pretrained Inception'\n",
    "output_path = root / 'Models' / 'Pretrained Inception' / 'Image Features Batches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31d7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "def get_pretrained_inceptionV3():\n",
    "    ## Initializing Pre-trained Model\n",
    "    model = InceptionV3(weights='imagenet')\n",
    "    ## Removing Softmax, as the problem is not about classification\n",
    "    model2 = Model(model.input, model.layers[-2].output)\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d39cf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3 = get_pretrained_inceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031c0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_pretrained_inception(inputs, model, batch_size = 64, show_progress = True):\n",
    "    \n",
    "    keys = list(inputs.keys())\n",
    "    values = list(inputs.values())\n",
    "    \n",
    "    features = {}\n",
    "    index = 0\n",
    "    \n",
    "    while index + batch_size < len(keys):\n",
    "        if show_progress:\n",
    "            print('extracted ' + str(index) + ' image features out of ' + str(len(keys)))\n",
    "            \n",
    "        batch = np.array(values[index:index+batch_size])\n",
    "        feature_batch = model.predict(batch, verbose = 0, batch_size = 64)\n",
    "        \n",
    "        for num, feature in enumerate(feature_batch):\n",
    "            features[keys[index + num]] = feature\n",
    "        \n",
    "        index += batch_size\n",
    "    \n",
    "    batch = np.array(values[index:])\n",
    "    feature_batch = model.predict(batch, verbose = 0, batch_size = 64)\n",
    "    for num, feature in enumerate(feature_batch):\n",
    "            features[keys[index + num]] = feature\n",
    "    \n",
    "    return features\n",
    "        #encoded_batch = model.predict(inputs[key], batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf74d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = glob.glob(str(preprocessed_image_path) + '\\*')\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94726ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a long time!!! Around 1 hour in my settings\n",
    "count_train = 0\n",
    "count_test = 0\n",
    "for path in paths:\n",
    "    #print(path)\n",
    "    tmp = np.load(path, allow_pickle=True).item()\n",
    "    gc.collect()\n",
    "    \n",
    "    if 'train' in path:\n",
    "        train_features = get_features_pretrained_inception(tmp, inceptionV3, batch_size = len(tmp))\n",
    "        np.save(output_path / ('train_features_batch_' + str(count_train)), train_features)\n",
    "        count_train += 1\n",
    "    \n",
    "    else:\n",
    "        test_features = get_features_pretrained_inception(tmp, inceptionV3, batch_size = len(tmp))\n",
    "        np.save(output_path / ('test_features_batch_'+ str(count_test)), test_features)\n",
    "        count_test += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e148f00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all batches into one big thing \n",
    "# This is possible because the feature extraction reduces dimensionality significantly\n",
    "paths = glob.glob(str(output_path) + '\\*')\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad7be663",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = {}\n",
    "test_features = {}\n",
    "\n",
    "for path in paths:\n",
    "    tmp = np.load(path, allow_pickle=True).item()\n",
    "    if 'train_' in path:\n",
    "        train_features = train_features | tmp\n",
    "    else:\n",
    "        test_features = test_features | tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ea6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(model_path / 'train_features_full', train_features)\n",
    "np.save(model_path / 'test_features_full', test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This takes a long time!!!\n",
    "# print('--- Extracting Train Image Features ---')\n",
    "# for path in paths:\n",
    "#     if 'train' in path:\n",
    "#         tmp = np.load()\n",
    "# train_features = get_features_pretrained_inception(train_images_preprocessed, inceptionV3, batch_size = 128)\n",
    "# np.save(output_path + 'train_features', train_features)\n",
    "\n",
    "# print('--- Extracting Test Image Features ---')\n",
    "# test_features = get_features_pretrained_inception(test_images_preprocessed, inceptionV3, batch_size = 128)\n",
    "# np.save(output_path + 'test_features', test_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
