{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca1282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5c365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.absolute()) \n",
    "\n",
    "preprocessed_image_path = root / 'Shared Preprocessed Objects' / 'Preprocessed Images for Inception'\n",
    "fetching_path = root / 'Shared Preprocessed Objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7bd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = np.load(fetching_path / \"train_image_paths.npy\", allow_pickle=True)\n",
    "test_image_paths = np.load(fetching_path / \"test_image_paths.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd2827e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 50\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image_paths), len(test_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28433241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecated because of extreme long time to run and OOM issues\n",
    "'''def preprocess_images_inceptionV3(image_paths, batch_size = 32, show_progress = True):\n",
    "    features = {}\n",
    "    index = 0\n",
    "    \n",
    "    while index + batch_size < len(image_paths):\n",
    "        \n",
    "        if show_progress:\n",
    "            print('extracted ' + str(index) + ' image features out of ' + str(len(image_paths)))\n",
    "            \n",
    "        batch = image_paths[index:index+batch_size]\n",
    "        img_batch = preprocess_image_batch(batch)\n",
    "        #encoded_batch = model.predict(img_batch, batch_size = batch_size)\n",
    "        \n",
    "        for num, path in enumerate(batch):\n",
    "            imageId = path[path.index('ROCO_'):-4]\n",
    "            features[imageId] = img_batch[num]\n",
    "        \n",
    "        index += batch_size\n",
    "    \n",
    "    batch = image_paths[index:]\n",
    "    img_batch = preprocess_image_batch(batch)\n",
    "    for num, path in enumerate(batch):\n",
    "        imageId = path[path.index('ROCO_'):-4]\n",
    "        features[imageId] = img_batch[num]\n",
    "    \n",
    "    return features'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e8977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess image batch so that it can be input into InceptionV3.\n",
    "def preprocess_image_batch(images_path):\n",
    "    tmp = []\n",
    "    \n",
    "    for image_path in images_path:\n",
    "        img = image.load_img(image_path, target_size = (299,299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x = preprocess_input(x)\n",
    "        \n",
    "        tmp.append(np.array(x))\n",
    "    \n",
    "    tmp = np.array(tmp)\n",
    "    tmp = tmp.reshape((len(images_path), 299, 299, 3))\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "355e51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_batch_inceptionV3(image_paths, file_prefix, batch_size = 32, show_progress = True):\n",
    "    \n",
    "    index = 0\n",
    "    batch_count = 0\n",
    "    while index + batch_size < len(image_paths):\n",
    "        # Get image paths \n",
    "        paths = glob.glob(str(preprocessed_image_path) + '\\*')\n",
    "        paths = [re.sub('\\\\\\\\', '//', path) for path in paths]\n",
    "        paths = '\\t'.join(paths)\n",
    "        \n",
    "        # Checking if the file already exists since this is very slow\n",
    "        # If the file already exists, skip this step. This is done because this takes a long time\n",
    "        # and you may face timeouts from colab, for example\n",
    "        if str(preprocessed_image_path) + file_prefix + str(batch_count) in paths:\n",
    "            print('skipped file ' + preprocessed_image_path + file_prefix + str(batch_count) + ' because it already exists')\n",
    "            index += batch_size\n",
    "            batch_count += 1\n",
    "        \n",
    "        # If it doesnt exist, then create it\n",
    "        else:\n",
    "            features = {}\n",
    "            gc.collect()\n",
    "            start = time.time()\n",
    "            \n",
    "            # Define the batch\n",
    "            batch = image_paths[index:index+batch_size]\n",
    "            # Preprocess images\n",
    "            img_batch = preprocess_image_batch(batch)\n",
    "            \n",
    "            # store on dict dict\n",
    "            for num, path in enumerate(batch):\n",
    "                imageId = path[path.index('ROCO_'):-4]\n",
    "                features[imageId] = img_batch[num]\n",
    "            \n",
    "            # Save\n",
    "            np.save(preprocessed_image_path / (file_prefix + str(batch_count)), features)\n",
    "\n",
    "            index += batch_size\n",
    "            batch_count += 1\n",
    "\n",
    "            if show_progress:\n",
    "                print('Preprocessed ' + str(index) + ' images out of ' + str(len(image_paths)))\n",
    "                print('Took ' + str(time.time() - start) + ' seconds to process this batch')\n",
    "    \n",
    "    # Save last Batch one-by-one\n",
    "    features = {}\n",
    "    batch = image_paths[index:]\n",
    "    img_batch = preprocess_image_batch(batch)\n",
    "    for num, path in enumerate(batch):\n",
    "        imageId = path[path.index('ROCO_'):-4]\n",
    "        features[imageId] = img_batch[num]\n",
    "    \n",
    "    np.save(preprocessed_image_path / (file_prefix + str(batch_count)), features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b351f91b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preprocessing Train Images ---\n",
      "Preprocessed 10 images out of 100\n",
      "Took 0.09227919578552246 seconds to process this batch\n",
      "Preprocessed 20 images out of 100\n",
      "Took 0.08899879455566406 seconds to process this batch\n",
      "Preprocessed 30 images out of 100\n",
      "Took 0.11802840232849121 seconds to process this batch\n",
      "Preprocessed 40 images out of 100\n",
      "Took 0.0854032039642334 seconds to process this batch\n",
      "Preprocessed 50 images out of 100\n",
      "Took 0.09400343894958496 seconds to process this batch\n",
      "Preprocessed 60 images out of 100\n",
      "Took 0.10695528984069824 seconds to process this batch\n",
      "Preprocessed 70 images out of 100\n",
      "Took 0.09799742698669434 seconds to process this batch\n",
      "Preprocessed 80 images out of 100\n",
      "Took 0.09999752044677734 seconds to process this batch\n",
      "Preprocessed 90 images out of 100\n",
      "Took 0.07800102233886719 seconds to process this batch\n",
      "--- Preprocessing Test Images ---\n",
      "Preprocessed 10 images out of 50\n",
      "Took 0.10400581359863281 seconds to process this batch\n",
      "Preprocessed 20 images out of 50\n",
      "Took 0.09299874305725098 seconds to process this batch\n",
      "Preprocessed 30 images out of 50\n",
      "Took 0.08299517631530762 seconds to process this batch\n",
      "Preprocessed 40 images out of 50\n",
      "Took 0.07196855545043945 seconds to process this batch\n"
     ]
    }
   ],
   "source": [
    "# This takes a long time!!! Around 3 hours on my personal setting\n",
    "print('--- Preprocessing Train Images ---')\n",
    "sample_train_images_preprocessed = preprocess_image_batch_inceptionV3(train_image_paths, 'train_images_preprocessed_batch_', batch_size = 10)\n",
    "\n",
    "print('--- Preprocessing Test Images ---')\n",
    "sample_test_images_preprocessed = preprocess_image_batch_inceptionV3(test_image_paths, 'test_images_preprocessed_batch_', batch_size = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f64bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
