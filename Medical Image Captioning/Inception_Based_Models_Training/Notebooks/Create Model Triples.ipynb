{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b60fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05750bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.absolute())\n",
    "\n",
    "model_path = root / 'Models' / 'Retrained Inception'\n",
    "fetching_path = root / 'Shared Preprocessed Objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427eedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Index = np.load(fetching_path / \"word2Index.npy\", allow_pickle=True).item()\n",
    "variable_params = np.load(fetching_path / \"variable_params.npy\", allow_pickle=True).item()\n",
    "\n",
    "train_captions = np.load(fetching_path / \"train_captions.npy\", allow_pickle=True).item()\n",
    "test_captions = np.load(fetching_path / \"test_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "train_features = np.load(model_path / \"train_features_full.npy\", allow_pickle=True).item()\n",
    "test_features = np.load(model_path / \"test_features_full.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e779f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(model_path / 'training_triples')\n",
    "os.mkdir(model_path / 'test_triples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36790b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch(X1, X2, y, path, batch):\n",
    "    np.save(path / ('features_batch_' + str(batch)), np.array(X1))\n",
    "    np.save(path / ('captions_batch_' + str(batch)), np.array(X2))\n",
    "    np.save(path / ('outputs_batch_' + str(batch)), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17841eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def save_LSTM_triples_batches(path, features, captions, word2Index, max_len, vocab_size, batch_size = 2048, show_progress = True):\n",
    "    ''' This function generates the triples (feature, caption up until a certain word, next word of the true caption) that will be used to train the LSTM model. may take a minute to run.\n",
    "    If batch_size > len(features) then it will generate only one batch. This is not very advisable, however, because this may cause OOM problems during training and even in this function.'''\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    y  = []\n",
    "    \n",
    "    batch = 0\n",
    "    count = 0\n",
    "    for key in features:\n",
    "        count += 1\n",
    "        # Fetching features and captions\n",
    "        image_features = features[key]\n",
    "        caption = captions[key]\n",
    "        \n",
    "        # Encoding caption\n",
    "        seq = [word2Index[word] for word in caption.split(' ') if word in word2Index]\n",
    "        \n",
    "        # Splitting encoded sequence into X,y pair\n",
    "        for i in range(1, len(seq)):\n",
    "            # input-output pair split\n",
    "            input_seq, output_seq = seq[:i], seq[i]\n",
    "            # padding input sequence\n",
    "            input_seq = pad_sequences([input_seq], maxlen=max_len, padding = 'post')[0]\n",
    "            # encoding output Sequence\n",
    "            output_seq = to_categorical([output_seq], num_classes=vocab_size)[0]\n",
    "            \n",
    "            # appending and storage\n",
    "            X1.append(image_features)\n",
    "            X2.append(input_seq)\n",
    "            y.append(output_seq)\n",
    "\n",
    "        if count % batch_size == 0:\n",
    "            # Save current batch\n",
    "            save_batch(X1, X2, y, path, batch)\n",
    "            \n",
    "            # Reset Batch\n",
    "            X1 = []\n",
    "            X2 = []\n",
    "            y  = []\n",
    "            gc.collect()\n",
    "            \n",
    "            batch += 1\n",
    "            print('Treated ' + str(batch_size*batch) + ' images out of ' + str(len(features)))\n",
    "\n",
    "    save_batch(X1, X2, y, path, batch)\n",
    "    \n",
    "    return batch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8c3943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treated 9 images out of 100\n",
      "Treated 18 images out of 100\n",
      "Treated 27 images out of 100\n",
      "Treated 36 images out of 100\n",
      "Treated 45 images out of 100\n",
      "Treated 54 images out of 100\n",
      "Treated 63 images out of 100\n",
      "Treated 72 images out of 100\n",
      "Treated 81 images out of 100\n",
      "Treated 90 images out of 100\n",
      "Treated 99 images out of 100\n",
      "Treated 9 images out of 50\n",
      "Treated 18 images out of 50\n",
      "Treated 27 images out of 50\n",
      "Treated 36 images out of 50\n",
      "Treated 45 images out of 50\n"
     ]
    }
   ],
   "source": [
    "# Also takes a long time. Around 30 minutes \n",
    "# Saving training triples\n",
    "num_batches_training = save_LSTM_triples_batches(model_path / 'training_triples', train_features, \n",
    "                                   train_captions, word2Index, variable_params['max_caption_len'], \n",
    "                                   variable_params['vocab_size'], batch_size = 9)\n",
    "\n",
    "# Saving test triples. I am not sure this is required.\n",
    "num_batches_test = save_LSTM_triples_batches(model_path / 'test_triples', test_features, \n",
    "                                   test_captions, word2Index, variable_params['max_caption_len'], \n",
    "                                   variable_params['vocab_size'], batch_size = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696e821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
