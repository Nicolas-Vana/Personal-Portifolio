{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8RwSLQxDJh_c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tvrf1L6KJo09",
    "outputId": "18545d34-abb3-46d8-96a9-c175fbb248b9"
   },
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.parent.absolute())\n",
    "\n",
    "preprocessed_image_path = root / 'Shared Preprocessed Objects' / 'Preprocessed Images for Inception'\n",
    "model_path = root / 'Models' / 'Retrained Inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xuon82B3LB1w"
   },
   "outputs": [],
   "source": [
    "# preprocessed_train_path = '/content/drive/MyDrive/Applications of Deep Learning - Medical Image Captioning/ROCOfull/Train/Inception_Preprocessed_Train'\n",
    "# preprocessed_test_path = '/content/drive/MyDrive/Applications of Deep Learning - Medical Image Captioning/ROCOfull/Test/Inception_Preprocessed_Test'\n",
    "\n",
    "# save_train =  '/content/drive/MyDrive/Applications of Deep Learning - Medical Image Captioning/ROCOfull/Train/Retrained_Inception_Features/'\n",
    "# save_test =  '/content/drive/MyDrive/Applications of Deep Learning - Medical Image Captioning/ROCOfull/Test/Retrained_Inception_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vTuJX7QJpUI",
    "outputId": "273cc12e-ab33-4ae5-b0c4-9ec6661c1bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 745)               1526505   \n",
      "=================================================================\n",
      "Total params: 23,329,289\n",
      "Trainable params: 23,294,857\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(model_path / 'Retrained_Inception' / 'epoch=2') # Choose best epoch\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gK6JgrxuKxuE"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import gc\n",
    "\n",
    "def extract_features_retrained_inception(model, path, path_save, train_test, batch_size = 32):\n",
    "  files = glob.glob(str(path) + '/*')\n",
    "  #print(files)\n",
    "\n",
    "  for batch, file in enumerate(files):\n",
    "    if train_test not in file:\n",
    "        continue\n",
    "    \n",
    "    print('Extracting Features Batch = ' + str(batch))\n",
    "    features = {}\n",
    "    preprocessed_images = np.load(file, allow_pickle = True).item()\n",
    "    imageIds = preprocessed_images.keys()\n",
    "    images = np.array(list(preprocessed_images.values()))\n",
    "    gc.collect()\n",
    "    #print(len(imageIds), images.shape)\n",
    "\n",
    "    extracted_features = model.predict(images, batch_size = 32, verbose = 1)\n",
    "\n",
    "    for index, imageId in enumerate(imageIds):\n",
    "      features[imageId] = extracted_features[index]\n",
    "    \n",
    "    #print(extracted_features.shape, features)\n",
    "    \n",
    "    if train_test == 'train':\n",
    "        np.save(path_save / 'Train Features' / ('features_batch_' + str(batch)), features, allow_pickle = True)\n",
    "    else:\n",
    "        np.save(path_save / 'Test Features' / ('features_batch_' + str(batch)), features, allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RN8tfeHcMS-S",
    "outputId": "04f96f4b-22a1-4abe-cd7c-d06a5f188dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features Batch = 5\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Extracting Features Batch = 6\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Extracting Features Batch = 7\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Extracting Features Batch = 8\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Extracting Features Batch = 9\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Extracting Features Batch = 10\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Extracting Features Batch = 11\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Extracting Features Batch = 12\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Extracting Features Batch = 13\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Extracting Features Batch = 14\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Extracting Features Batch = 0\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Extracting Features Batch = 1\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Extracting Features Batch = 2\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Extracting Features Batch = 3\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Extracting Features Batch = 4\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract train features using retrained inception on CUIs\n",
    "extract_features_retrained_inception(model, preprocessed_image_path, model_path, 'train')\n",
    "# Extract test features using retrained inception on CUIs\n",
    "extract_features_retrained_inception(model, preprocessed_image_path, model_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "APbGJvlaMXhh"
   },
   "outputs": [],
   "source": [
    "# This function merges all the features batches created earlier into one single dictionary. This is possible because of the dimensionality reduction from the \n",
    "# Preprocessed images with shape (X, 299, 299, 3) into the features with shape (X, cui_vocab_size), which is 745 for the models we are running.\n",
    "def Merge(dict1, dict2):\n",
    "    for i in dict2.keys():\n",
    "        dict1[i]=dict2[i]\n",
    "    return dict1\n",
    "\n",
    "def merge_feature_batches(path, train_test):\n",
    "    if train_test == 'train':\n",
    "        files = glob.glob(str(path) + '/Train Features/*')\n",
    "    else:\n",
    "        files = glob.glob(str(path) + '/Test Features/*')\n",
    "    features_full = {}\n",
    "\n",
    "    for file in files:\n",
    "        features = np.load(file, allow_pickle = True).item()\n",
    "\n",
    "        features_full = Merge(features_full, features)\n",
    "\n",
    "    print(len(features_full))\n",
    "    return features_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4uw4jNqUExf",
    "outputId": "8882dbb3-bed0-412b-8b8f-8ebecd59d619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "features_full_train = merge_feature_batches(model_path, 'train')\n",
    "np.save(model_path / 'train_features_full', features_full_train, allow_pickle=True)\n",
    "\n",
    "features_full_test = merge_feature_batches(model_path, 'test')\n",
    "np.save(model_path / 'test_features_full', features_full_test, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5WXAiB8VzGy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
