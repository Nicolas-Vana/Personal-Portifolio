{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea71d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32bb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.parent.absolute())\n",
    "\n",
    "preprocessed_image_path = root / 'Shared Preprocessed Objects' / 'Preprocessed Images for Inception' \n",
    "model_path = root / 'Models' / 'Retrained Inception'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477a4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cui2Index = np.load(model_path / \"cui2Index.npy\", allow_pickle=True).item()\n",
    "training_pairs = np.load(model_path / \"training_pairs.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca29f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_untrained_inceptionV3(vocab_size):\n",
    "    ## Initializing Pre-trained Model\n",
    "    inceptionInput = keras.Input(shape=(299,299,3), name=\"img\")\n",
    "    model = InceptionV3(weights=None, input_tensor = inceptionInput)\n",
    "    #model.summary()\n",
    "    ## Removing Softmax, as the problem is not about classification\n",
    "    model = Model(model.input, model.layers[-2].output)\n",
    "    \n",
    "    denseInput = keras.Input(shape=(2048,), name=\"denseInput\")\n",
    "    dense = tf.keras.layers.Dense(vocab_size, activation = 'sigmoid')(denseInput)#(model2.layers[-1].output)\n",
    "    model_dense = Model(denseInput, outputs=dense)\n",
    "\n",
    "\n",
    "    inceptionOut = model(inceptionInput)\n",
    "    denseOut = model_dense(inceptionOut)\n",
    "\n",
    "    model_final = Model(inputs = inceptionInput, outputs = denseOut)\n",
    "    model_final.compile(optimizer='adam',loss='binary_crossentropy')#tf.keras.losses.BinaryCrossentropy(from_logits=False))\n",
    "    model_final.summary()\n",
    "    \n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b20e9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 745)               1526505   \n",
      "=================================================================\n",
      "Total params: 23,329,289\n",
      "Trainable params: 23,294,857\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(cui2Index)\n",
    "untrained_inceptionV3 = get_untrained_inceptionV3(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e70411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def get_x_y_from_batch(images, cuis):\n",
    "    x, y = [], []\n",
    "    for imageId in images:\n",
    "        x.append(images[imageId])\n",
    "        y.append(cuis[imageId])\n",
    "    \n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def get_cui_matrix_from_training_pairs(images, training_pairs, vocab_size):\n",
    "    cuis_matrix = {}\n",
    "\n",
    "    for index, img in enumerate(images):\n",
    "        tmp = np.zeros(vocab_size)\n",
    "        \n",
    "        for value in training_pairs[img]:\n",
    "            tmp[value] = 1\n",
    "        \n",
    "        cuis_matrix[img] = tmp\n",
    "    \n",
    "    return cuis_matrix\n",
    "\n",
    "def training_loop(model, path, model_path, training_pairs, vocab_size, EPOCHS = 10, batch_size = 8):\n",
    "    preprocessed_paths = glob.glob(str(path) + '/*')\n",
    "    '''for index in range(len(preprocessed_paths)):\n",
    "        preprocessed_paths[index] = preprocessed_paths[index].replace('\\\\', '//')'''\n",
    "    #print(preprocessed_paths)\n",
    "\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print('---- EPOCH ' + str(epoch) + ' ----')\n",
    "        for count, path in enumerate(preprocessed_paths):\n",
    "            start = time.time()\n",
    "            if \"test\" in path:\n",
    "                continue\n",
    "            else:\n",
    "                images = np.load(path, allow_pickle = True).item()\n",
    "                \n",
    "                cuis = get_cui_matrix_from_training_pairs(images, training_pairs, vocab_size)\n",
    "                gc.collect()\n",
    "                x, y = get_x_y_from_batch(images, cuis)\n",
    "                gc.collect()\n",
    "            \n",
    "                #print(x.shape, y.shape)\n",
    "                \n",
    "                history.append(model.fit(x, y, batch_size = batch_size, verbose=1, validation_split = 0.05))\n",
    "                tf.keras.backend.clear_session()\n",
    "              \n",
    "            print(\"Total Time for Batch = \" + str(time.time() - start) + \" seconds\")\n",
    "        model.save(model_path / 'Retrained_Inception' / ('epoch=' + str(epoch)))\n",
    "    return model, np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52dc723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- EPOCH 0 ----\n",
      "2/2 [==============================] - 28s 7s/step - loss: 0.6942 - val_loss: 0.6842\n",
      "Total Time for Batch = 29.693770170211792 seconds\n",
      "2/2 [==============================] - 3s 732ms/step - loss: 0.2912 - val_loss: 0.6476\n",
      "Total Time for Batch = 4.064781427383423 seconds\n",
      "2/2 [==============================] - 3s 798ms/step - loss: 0.0905 - val_loss: 0.5868\n",
      "Total Time for Batch = 3.794854164123535 seconds\n",
      "2/2 [==============================] - 4s 829ms/step - loss: 0.0601 - val_loss: 0.5174\n",
      "Total Time for Batch = 4.4703240394592285 seconds\n",
      "2/2 [==============================] - 3s 790ms/step - loss: 0.0512 - val_loss: 0.4443\n",
      "Total Time for Batch = 3.548741340637207 seconds\n",
      "2/2 [==============================] - 3s 748ms/step - loss: 0.0725 - val_loss: 0.3403\n",
      "Total Time for Batch = 3.88904070854187 seconds\n",
      "2/2 [==============================] - 3s 713ms/step - loss: 0.0837 - val_loss: 0.2541\n",
      "Total Time for Batch = 3.6330909729003906 seconds\n",
      "2/2 [==============================] - 3s 732ms/step - loss: 0.0562 - val_loss: 0.1455\n",
      "Total Time for Batch = 3.45796275138855 seconds\n",
      "2/2 [==============================] - 4s 959ms/step - loss: 0.0670 - val_loss: 0.0909\n",
      "Total Time for Batch = 5.050282716751099 seconds\n",
      "2/2 [==============================] - 4s 922ms/step - loss: 0.0358 - val_loss: 0.0945\n",
      "Total Time for Batch = 4.498122453689575 seconds\n",
      "INFO:tensorflow:Assets written to: D:\\Mestrado\\Applications of Deep Learning\\Pull Request - Rename\\Models\\Retrained Inception\\Retrained_Inception\\epoch=0\\assets\n",
      "---- EPOCH 1 ----\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.0569 - val_loss: 0.0526\n",
      "Total Time for Batch = 8.523970127105713 seconds\n",
      "2/2 [==============================] - 5s 924ms/step - loss: 0.0561 - val_loss: 0.0279\n",
      "Total Time for Batch = 5.9887309074401855 seconds\n",
      "2/2 [==============================] - 11s 8s/step - loss: 0.0391 - val_loss: 0.0376\n",
      "Total Time for Batch = 11.852619886398315 seconds\n",
      "2/2 [==============================] - 4s 983ms/step - loss: 0.0452 - val_loss: 0.0759\n",
      "Total Time for Batch = 5.517204284667969 seconds\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.0425 - val_loss: 0.1686\n",
      "Total Time for Batch = 18.891780853271484 seconds\n",
      "2/2 [==============================] - 21s 9s/step - loss: 0.0616 - val_loss: 0.0868\n",
      "Total Time for Batch = 29.98294973373413 seconds\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.0597 - val_loss: 0.1355\n",
      "Total Time for Batch = 18.9427011013031 seconds\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.0535 - val_loss: 0.0960\n",
      "Total Time for Batch = 26.59731674194336 seconds\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.0528 - val_loss: 0.1783\n",
      "Total Time for Batch = 27.245712518692017 seconds\n",
      "2/2 [==============================] - 18s 8s/step - loss: 0.0364 - val_loss: 0.3082\n",
      "Total Time for Batch = 27.199899435043335 seconds\n",
      "INFO:tensorflow:Assets written to: D:\\Mestrado\\Applications of Deep Learning\\Pull Request - Rename\\Models\\Retrained Inception\\Retrained_Inception\\epoch=1\\assets\n",
      "---- EPOCH 2 ----\n",
      "2/2 [==============================] - 32s 17s/step - loss: 0.0531 - val_loss: 0.1682\n",
      "Total Time for Batch = 45.082258224487305 seconds\n",
      "2/2 [==============================] - 21s 10s/step - loss: 0.0451 - val_loss: 0.0807\n",
      "Total Time for Batch = 30.75502634048462 seconds\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0356"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25276/772920607.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muntrained_inceptionV3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_image_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'history'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25276/2483444585.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[1;34m(model, path, model_path, training_pairs, vocab_size, EPOCHS, batch_size)\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;31m#print(x.shape, y.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m                 \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1215\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = training_loop(untrained_inceptionV3, preprocessed_image_path, model_path, training_pairs, vocab_size)\n",
    "np.save(model_path / 'history', history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34548f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
