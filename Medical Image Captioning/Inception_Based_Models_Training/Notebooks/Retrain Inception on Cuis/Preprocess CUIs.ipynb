{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1057698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e574dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.parent.absolute())\n",
    "\n",
    "train_cuis_path = root / 'ROCO' / 'Data' / 'Train' / 'radiology' / 'cuis.txt'\n",
    "test_cuis_path = root / 'ROCO' / 'Data' / 'Test' / 'radiology' / 'cuis.txt'\n",
    "model_path = root / 'Models' / 'Retrained Inception'\n",
    "#fetching_path = root / 'Shared Preprocessed Objects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbed3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUI_FREQUENCY_CUTOFF = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f5a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_cuis(cuis_path):\n",
    "    doc = open(cuis_path, 'r', encoding = 'utf-8').read()\n",
    "    \n",
    "    cuis = {}\n",
    "    splitDoc = doc.split('ROCO')\n",
    "\n",
    "    splitDoc = ['ROCO' + x for x in splitDoc][1:]\n",
    "    splitDoc = [x.split('\\t') for x in splitDoc]\n",
    "    #splitDoc = [x.split('\\n') for x in splitDoc]\n",
    "\n",
    "    for index, line in enumerate(splitDoc):\n",
    "        splitDoc[index] = [re.sub('\\n', '', x) for x in line]#[x.split('\\n') for x in line]\n",
    "\n",
    "    for index, line in enumerate(splitDoc):\n",
    "        splitDoc[index] = [x for x in line if x != '']\n",
    "\n",
    "    for index, line in enumerate(splitDoc):\n",
    "        cuis[line[0]] = [x for x in line[1:]]\n",
    "\n",
    "    #splitDoc\n",
    "    return cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8194ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuis = get_cuis(train_cuis_path)\n",
    "#cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8439919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_cuis(cuis):\n",
    "    vocab = []\n",
    "    for img in cuis:\n",
    "        #captionSplit = caption.split(' ')\n",
    "        for cui in cuis[img]:\n",
    "            vocab.append(cui)\n",
    "    vocab = list(set(vocab))\n",
    "    return vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c53a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5817\n"
     ]
    }
   ],
   "source": [
    "cui_vocab = get_vocab_cuis(cuis)\n",
    "print(len(cui_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f592669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_cui_vocab(cuis, frequency_limit):\n",
    "    cui_counts = {}\n",
    "    \n",
    "    for img in cuis:\n",
    "        #num_sents +=1\n",
    "        for cui in cuis[img]:\n",
    "            if cui in cui_counts:\n",
    "                cui_counts[cui] += 1#word_counts.get(w, 0) + 1\n",
    "            else:\n",
    "                cui_counts[cui] = 0\n",
    "\n",
    "    vocab_reduced = [w for w in cui_counts if cui_counts[w]>=frequency_limit]\n",
    "\n",
    "    #print('Reduced Vocabulary size: ', len(vocab_reduced))\n",
    "    return vocab_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33de9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_cuis =  reduce_cui_vocab(cuis, CUI_FREQUENCY_CUTOFF)\n",
    "#reduced_cuis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9959fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cui_mapping(vocab_reduced):\n",
    "    index2Cui = {}\n",
    "    cui2Index = {}\n",
    "\n",
    "    index = 0\n",
    "    for w in vocab_reduced:\n",
    "        cui2Index[w] = index\n",
    "        index2Cui[index] = w\n",
    "        index += 1\n",
    "\n",
    "    return cui2Index, index2Cui, len(cui2Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6272768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cui2Index, index2Cui, cui_vocab_size = get_cui_mapping(reduced_cuis)\n",
    "cui_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200972ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(model_path / 'cui2Index', cui2Index)\n",
    "np.save(model_path / 'index2Cui', index2Cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21514dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cui_matrix(cuis, vocab_reduced, vocab_size, cui2Index):\n",
    "    training_pairs = {}\n",
    "    counter = 0\n",
    "    for img in cuis:\n",
    "        training_pairs[img] = [cui2Index[cui] for cui in cuis[img] if cui in vocab_reduced]\n",
    "        if len(training_pairs[img]) == 0:\n",
    "            counter += 1\n",
    "    \n",
    "    print(str(counter) + ' of the images used have 0 CUIs after the vocabulary reduction. Out of ' \n",
    "          + str(len(training_pairs)))\n",
    "    cuis_matrix = {}\n",
    "    #np.zeros((len(training_pairs), vocab_size))\n",
    "\n",
    "    for index, img in enumerate(training_pairs):\n",
    "        tmp = np.zeros(vocab_size)\n",
    "        for value in training_pairs[img]:\n",
    "            tmp[value] = 1\n",
    "        cuis_matrix[img] = tmp\n",
    "        #cuis_matrix[index][training_pairs[img]] = 1\n",
    "\n",
    "    return training_pairs, cuis_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca72923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096 of the images used have 0 CUIs after the vocabulary reduction. Out of 65450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65450"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pairs, cuis_matrix = get_cui_matrix(cuis, reduced_cuis, cui_vocab_size, cui2Index)\n",
    "len(cuis_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4862a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(model_path / 'training_pairs', training_pairs)\n",
    "np.save(model_path / 'cuis_matrix', cuis_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf6ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
