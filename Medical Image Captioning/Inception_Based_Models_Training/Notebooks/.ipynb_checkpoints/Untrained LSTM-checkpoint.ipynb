{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb0f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954648d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Mestrado/Applications of Deep Learning/Pull Request - Rename/Models/Pretrained Inception')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(os.getcwd())\n",
    "root = Path(path.parent.absolute())\n",
    "\n",
    "glove_path = root / 'Glove'\n",
    "model_path = root / 'Models' / 'Pretrained Inception'\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15dce203",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'D://Mestrado//Applications of Deep Learning//Glove'\n",
    "target_path =  'D://Mestrado//Applications of Deep Learning//Compartmentalized_Models//Pretrained_Imagenet//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d549700",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Index = np.load(model_path + \"word2Index.npy\", allow_pickle=True).item()\n",
    "variable_params = np.load(model_path + \"variable_params.npy\", allow_pickle=True).item()\n",
    "train_features = np.load(model_path + \"train_features.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d0fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200  # Or 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f19314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embedding_matrix(glove_path, embedding_dim, word2Index, vocab_size):\n",
    "    ## Mapping to embedding dimension GLOVE vector\n",
    "    embeddings_ix = {}\n",
    "\n",
    "    f = open(glove_path + '//glove.6B.' + str(embedding_dim) + 'd.txt', encoding = 'utf-8')\n",
    "\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word   = values[0]\n",
    "        coefficients = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_ix[word] = coefficients\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    for word, i in word2Index.items():\n",
    "        embedding_vector = embeddings_ix.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "133c46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix(glove_path, EMBEDDING_DIM, word2Index, variable_params['vocab_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e78af",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(model_path + 'embedding_matrix', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240a63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, Activation, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_LSTM_model(features_shape, vocab_size, max_len, embedding_matrix, embedding_dim):\n",
    "    inputs1 = Input(shape = features_shape, name = 'features')\n",
    "    fe1     = Dropout(0.6)(inputs1)\n",
    "    fe2     = Dense(256, 'relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape = (max_len), name = 'captions')\n",
    "    se1     = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
    "    se2     = Dropout(0.5)(se1)\n",
    "    se3     = LSTM(256)(se2)\n",
    "\n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, 'relu')(decoder1)\n",
    "    outputs  = Dense(vocab_size, 'softmax')(decoder2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs = outputs)\n",
    "\n",
    "    model.layers[2].set_weights([embedding_matrix])\n",
    "    model.layers[2].trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4baeadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shape = train_features[list(train_features.keys())[0]].shape\n",
    "features_shape\n",
    "\n",
    "features_shape = 745"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb46b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "captions (InputLayer)           [(None, 341)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 745)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 341, 200)     894200      captions[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 745)          0           features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 341, 200)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          190976      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          467968      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4471)         1149047     dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,767,983\n",
      "Trainable params: 1,873,783\n",
      "Non-trainable params: 894,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = get_LSTM_model(features_shape, variable_params['vocab_size'], variable_params['max_caption_len'], embedding_matrix, EMBEDDING_DIM)\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfeab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D://Mestrado//Applications of Deep Learning//Compartmentalized_Models//Retrained_Imagenet//UntrainedLSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D://Mestrado//Applications of Deep Learning//Compartmentalized_Models//Retrained_Imagenet//UntrainedLSTM\\assets\n",
      "C:\\Users\\nicol\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.save('D://Mestrado//Applications of Deep Learning//Compartmentalized_Models//Retrained_Imagenet//UntrainedLSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a08d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
