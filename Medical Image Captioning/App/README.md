This folder contains all the files and folder to build and run a streamlit app that displays the captioning generated by the 3 different models considered in this project.

Two of the use the InceptionV3 architecture to do feature extraction and then generate the captions using an LSTM model. The difference between these two is that the first one uses InceptionV3 trained on ImageNet data and outputs 2048 features. The second one is based on a retrained version of InceptionV3 that uses the CUI data from the ROCO dataset to extract 745 features from the images. The final model is a transformer based on VIT and RoBERTa.

Because of github file size limitations the data for the models was removed and has to be included under the "Transformer/Image_Cationing_VIT_Roberta_iter2/" and "Inception/RetrainedInceptionFeatureExtraction/" folders.

In this build the user can generate captions for some sample images from the ROCO dataset or upload their own image. He is also prompted to choose a model that should be used for the caption generation.

![Alt text](Examples/ROCO_00016.png?raw=true "ROCO_00016.png")

True caption - Axial source image from an intracranial magnetic resonance angiogram reveals abnormal arterial signal elevation in the left more than right cavernous sinuses consistent with a carotid cavernous fistula, as indicated by the arrow.

Pretrained - magnetic resonance imaging of the brain showing a welldefined lesion in the right frontal lobe

Retrained - magnetic resonance imaging of the brain showing a mass in the left frontal lobe

Transformer - t2weighted magnetic resonance image of the brain showing a large mass in the left side of the right side

As seen, the models are not capable of generating in-depth descriptions of the images and diagnostics identified in the true captions, showing some serious limitations in its applications. However, most of the time, the models are capable of correctly identifying the type of medical image presented and the major anamotical features of the image.   
